{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02642d82-507a-49eb-904a-c0dbd1962775",
   "metadata": {},
   "source": [
    "## Introduccion \n",
    "Eigenfaces (en español caras propias) es el nombre dado a un conjunto de autovectores cuando se utiliza en el problema de visión artificial del reconocimiento de rostros humanos. Matthew Turk y Alex Pentland lo propusieron en su paper en la clasificación de caras.\n",
    "\n",
    "Esta notebook muestra como hacer el cálculo del Análisis en Componentes Principales para los datos de los rostros, y luego aplicarlos para la reducción del espacio. Con este nuevo espacio se realizan dos tareas: reconstrucción y clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb98fc1-dd56-4159-ab75-0c918d68c94e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msio\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd24c45-e17f-4d54-9eef-600f74957584",
   "metadata": {},
   "source": [
    "Definición de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e2386-4cd6-4491-a47e-adff45b43d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(data, label):\n",
    "    # split dataset en entrenamiento y test\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for train, test in skf.split(data.T, label.T):\n",
    "        break\n",
    "    train_data = data[:,train]\n",
    "    train_lab = label[:,train]\n",
    "    test_data = data[:,test]\n",
    "    test_lab = label[:,test]\n",
    "    \n",
    "    return train_data, train_lab, test_data, test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1011cc2-fa88-4c3e-a7e4-b66fb84c6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPic(data, idx, dx=38):\n",
    "    # graficamos una rotro\n",
    "    v = data[:,idx] # primera columna\n",
    "    m = v.reshape((dx,dx)).T\n",
    "    plt.imshow(m, cmap=plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70853c63-f790-4463-9294-bacc688811fa",
   "metadata": {},
   "source": [
    "La lectura del archivo de datos nos devuelve dos matrices, una correspondiente a las imágenes de los rostros y la otra a un label que indica a cual\n",
    "persona pertenece la imágen.\n",
    "\n",
    "<img src=\"image_vector.png\" />\n",
    "\n",
    "Como vemos en la figura, las imágenes se convirtieron a vector, con N=38 para este set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160e755-39d7-41eb-8204-f6dcaeca4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('matlab/base_40_38_10.mat')\n",
    "# data es una matriz de 1444 x 380.\n",
    "# Corresponde a figuras de caras de tamanio 38x38 pixeles\n",
    "data = mat['data']\n",
    "label = mat['label']\n",
    "# extraemos la dimensionalidad de data, donde n es la cantidad de ejemplos, y d la dimensión del espacio.\n",
    "d, n = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f525e-5b3b-4e94-9f52-407c61e84835",
   "metadata": {},
   "source": [
    "## ACP\n",
    "\n",
    "Primero centramos los valores de las imágenes, restando la media.\n",
    "Luego calculamos la matriz de covarianzas:\n",
    "\n",
    "\n",
    "$C = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu) (x_i - \\mu)^{T}$\n",
    "\n",
    "Finalmente encontramos los autovalores y autovectores de esta matriz, los cuales ordenamos de mayor a menor valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f2f3d-5bbd-458b-86ce-00d5ad392754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculoACP(data):\n",
    "    d, n = data.shape\n",
    "    m=np.mean(data, axis=1)\n",
    "\n",
    "    X = data - np.tile(m.reshape((len(m), 1)), (1, n))\n",
    "    Mcov = np.dot(X,X.T) / n # Covariance Matrix\n",
    "\n",
    "    D, V = np.linalg.eigh(Mcov)\n",
    "\n",
    "    # ordenamos los autovalores de mayor a menor\n",
    "    idx = np.argsort (- D )\n",
    "    D = D[idx]\n",
    "    V = V[:, idx]\n",
    "\n",
    "    return D, V, X, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45d1ad-37ac-4adc-8154-61fdf51bd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, V, data_ref, m = calculoACP(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60094b9c-d2e1-450d-9a90-0e8225f0445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "showPic(V, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9373beb-09f5-4d77-8141-f9eac54469a5",
   "metadata": {},
   "source": [
    "El espacio de proyección del ACP esta compuesto por el vector V que es de tamaño $n \\times n$.\n",
    "\n",
    "El próximo paso busca la reducción del espacio de proyección, para quedarnos con aquellos autovectores en V que acumulen la mayor cantidad de información posible en las distintas direcciones.\n",
    "\n",
    "Para ello se hace un cómputo de la varianza acumulada en el vector D, y se selecciona una cantidad que signifique representar un 95 % de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19124b3d-29e5-49f2-95e9-4880c220190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.cumsum(D) / np.sum(D)\n",
    "plt.plot(ratio)\n",
    "x = np.where(ratio > 0.95)[0]\n",
    "M = x[0]\n",
    "\n",
    "print('Cantidad de autovectores de representación al 95 %: ', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e8470-ac8f-425a-8323-7b92961c0d2e",
   "metadata": {},
   "source": [
    "## RECONSTRUCCIÓN\n",
    "\n",
    "El hecho que quedarse con menos autovectores para la proyección del espacio, conlleva a una reducción de almacenamiento de la información, pero al mismo tiempo a cometer un error al tratar de reconstruir la imagen original.\n",
    "\n",
    "En este tramo de código representamos visualmente la imagen original y la reconstruida con M autovectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0825a6-5852-48c3-9a24-d48a3a067b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruccion\n",
    "im_orig = data_ref[:,0]\n",
    "cpM = im_orig @ V[:,0:M]\n",
    "im_rec = V[:,0:M] @ cpM \n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(im_orig.reshape((38,38)).T, cmap=plt.cm.gray)\n",
    "axes[1].imshow(im_rec.reshape((38,38)).T, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6713a37-6a78-416c-8ae2-61cfc9b29a2b",
   "metadata": {},
   "source": [
    "## CLASIFICACIÓN\n",
    "\n",
    "La tarea de clasificación en predecir a quien de las personas de la base de conocimientos pertenece un rostro de testing. Esto lo vamos a realizar gracias a proyectar el rostro de entrada al espacio de ACP y calcular por distancias, cual es rostro más cercano.\n",
    "\n",
    "En primer lugar separamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f03d14-0bea-421c-98c0-c302006d7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clasificacion\n",
    "train_data, train_lab, test_data, test_lab = splitDataset(data, label)\n",
    "Dt, Vt, train_ref, m = calculoACP(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d51b7-061f-4380-a5c3-2214eef590e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.cumsum(Dt) / np.sum(Dt)\n",
    "plt.plot(ratio)\n",
    "x = np.where(ratio > 0.95)[0]\n",
    "M = x[0]\n",
    "print('Cantidad de autovectores de representación al 95 % de la base de entrenamiento: ', M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93376-6f8a-4b67-8916-91ff54b44caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clf = train_ref.T @ Vt[:,0:M]   # proyectamos a la base de entrenamiento, de los cuales conocemos a que persona pertenece\n",
    "\n",
    "input_test = test_data[:,0] # vamos a clasificar el primer sujeto de la base de test\n",
    "test_acp = (input_test - m) @ Vt[:,0:M]    # le resto la media y proyecto en el espacio reducido de Vt\n",
    "Q = np.tile(test_acp.reshape((1,-1)), (data_clf.shape[0], 1))  \n",
    "dist = np.linalg.norm(data_clf - Q, axis=1)    # calculo las distancias a cada una de las imágenes de conocimientos proyectadas en el espacio ACP.\n",
    "y = np.argmin(dist)                             # clasificar por el más cercano\n",
    "\n",
    "if test_lab[0][0] == train_lab[0][y]:\n",
    "    print('Clasificacion correcta')\n",
    "else:\n",
    "    print('clasificacion incorrecta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d01616-3059-47c7-8460-6939288bb2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
